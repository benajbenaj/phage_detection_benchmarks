(PROFILES,) = glob_wildcards(config["bracken_dir"] + "/{p}.txt")


rule all:
    input:
        expand(
            "{b}/{p}_{m}/bin.1.fa",
            b=config["bins_dir"],
            p=PROFILES,
            m=config["model"],
        ),
        expand(
            "{b}/{p}_{m}_blast_out.txt",
            b=config["blast_out_dir"],
            p=PROFILES,
            m=config["model"],
        ),


# Create profile for InSilicoSeq, and file globs to find necessary genomes
rule make_profiles:
    input:
        config["bracken_dir"] + "/{id}.txt",
    output:
        config["profiles_dir"] + "/{id}_profile.txt",
        config["profiles_dir"] + "/{id}_files.txt",
    params:
        bracken_profiler=config["bracken_profiler"],
        refseq=config["refseq_info"],
        out_dir=config["profiles_dir"],
        time=config["make_profiles_time"],
    threads: config["make_profiles_ntasks"]
    shell:
        """
        {params.bracken_profiler} \
            -t {params.refseq} \
            -o {params.out_dir} \
            {input}
        """


# Concatenate input genomes for InSilicoSeq
rule cat_genomes:
    input:
        config["profiles_dir"] + "/{id}_files.txt",
    output:
        config["profiles_dir"] + "/{id}_genomes.fasta",
    params:
        cat_genomes=config["cat_genomes"],
        out_dir=config["profiles_dir"],
        parent=config["refseq_dir"],
        time=config["cat_genomes_time"],
    threads: config["cat_genomes_ntasks"]
    shell:
        """
        {params.cat_genomes} \
            -p {params.parent} \
            -o {params.out_dir} \
            {input}
        """


# Run InSilicoSeq to create simulated reads
rule simulate_reads:
    input:
        genomes=config["profiles_dir"] + "/{id}_genomes.fasta",
        abundances=config["profiles_dir"] + "/{id}_profile.txt",
    output:
        config["simulated_dir"] + "/{id}_{model}_R1.fastq",
        config["simulated_dir"] + "/{id}_{model}_R2.fastq",
    params:
        simulator=config["simulator"],
        env=config["iss_env"],
        reads=config["n_reads"],
        out_dir=config["simulated_dir"],
        time=config["simulate_reads_time"],
    threads: config["simulate_reads_ntasks"]
    shell:
        """
        source activate {params.env}
        {params.simulator} {params.reads} \
            --cpus {threads} \
            --model {wildcards.model} \
            --abundance_file {input.abundances} \
            --output {params.out_dir}/{wildcards.id}_{wildcards.model} \
            --genomes {input.genomes}
        """


# Assemble simulated reads into contigs with MegaHit
rule megahit_assembly:
    input:
        fwd=config["simulated_dir"] + "/{id}_{model}_R1.fastq",
        rev=config["simulated_dir"] + "/{id}_{model}_R2.fastq",
    output:
        config["contigs_dir"] + "/{id}_{model}/final.contigs.fa",
    params:
        megahit=config["megahit"],
        env=config["megahit_env"],
        out_dir=config["contigs_dir"],
        time=config["assembly_time"],
    threads: config["assembly_ntasks"]
    shell:
        """
        source activate {params.env}
        # Snakemake creates the out_dir, but megahit fails if it exists. So remove it.
        rm -rf {params.out_dir}/{wildcards.id}_{wildcards.model}
        {params.megahit} \
            -1 {input.fwd} \
            -2 {input.rev} \
            -o {params.out_dir}/{wildcards.id}_{wildcards.model}
        """


# Bin contigs from simulated reads
rule metabat_binning:
    input:
        in_file=config["contigs_dir"] + "/{id}_{model}/final.contigs.fa",
    output:
        config["bins_dir"] + "/{id}_{model}/bin.1.fa",
    params:
        metabat=config["metabat"],
        env=config["metabat_env"],
        out_dir=config["bins_dir"],
        time=config["binning_time"],
    threads: config["binning_ntasks"]
    shell:
        """
        source activate {params.env}
        if ![ -d {params.out_dir} ]; then
            mkdir {params.out_dir};
        fi
        {params.metabat} \
            -i {input.in_file} \
            -o {params.out_dir}/{wildcards.id}_{wildcards.model}/bin
        """


# Make BLAST databases from input genomes
rule make_blast_dbs:
    input:
        config["profiles_dir"] + "/{id}_genomes.fasta",
    output:
        directory(config["blast_dbs_dir"] + "/{id}/"),
    params:
        out_dir=config["blast_dbs_dir"],
        env=config["blast_env"],
        make_db=config["make_db"],
        time=config["make_db_time"],
    threads: config["make_db_ntasks"]
    shell:
        """
        source activate {params.env}
        {params.make_db} \
            -in {input} \
            -dbtype nucl \
            -out {params.out_dir}/{wildcards.id}/db \
            -title {wildcards.id}
        """


# Run BLAST querying assembled simulated reads against input genomes
rule run_blast:
    input:
        query=config["contigs_dir"] + "/{id}_{model}/final.contigs.fa",
        db=directory(config["blast_dbs_dir"] + "/{id}/"),
    output:
        config["blast_out_dir"] + "/{id}_{model}_blast_out.txt",
    params:
        out_dir=config["blast_out_dir"],
        env=config["blast_env"],
        e_value=config["e_value"],
        time=config["blast_time"],
        blast=config["blast"],
    threads: config["blast_ntasks"]
    shell:
        """
        source activate {params.env}
        {params.blast} \
            -query {input.query} \
            -db {input.db}/db \
            -out {output}
        """
